>Today's Lesson


### 딥러닝과 머신러닝의 차이

![머신러닝과 딥러닝](https://images.deepai.org/converted-papers/1808.00033/x2.png)

**전통적 머신러닝**: 
- 엔지니어가 손봐야 할 점이 많음.
- 정형화된 데이터를 우리가 어느정도 알고있는 알고리즘에 넘기기 때문에, 데이터의 양은 어느정도 패턴을 인지할 수 있을 정도만 있으면 충분함.
    
**딥러닝**: 
- 데이터가 아주 많아야 하고, 결과가 어떻게 나왔는지 설명하기가 어려움.
  - 이를 해결해줄 XAI(설명 가능한 인공지능)
 
### 자유도를 n-1로 주는 이유

모표준편차: 자유도 n 사용
  - 표본이 아닌, 모집단 전체를 알고 있어, 직접 계산할 수 있을 때
  - 모집단의 모든 데이터를 알고 있기 때문에 보정할 필요 없음
  - ex) 학교의 전체 학생의 시험 점수를 분석할 때
      - 회사의 모든 직원의 급여 데이터를 가지고 분석할 때
표본 표준편차: 자유도 n-1 사용
  - 데이터를 샘플(부분 데이터)로 수집했을 때
  - 모집단 전체를 알지 못하고, 샘플을 통해 모집단의 특성을 추정하려 할 때
  - 통계학에서 신뢰 구간이나 가설 검정을 수행할 때
  - ex) 연구에서 설문 조사나 샘플링된 데이터를 사용할 때
      - 모집단의 표준편차를 추정하려 할 때


[참고 글](https://bkshin.tistory.com/entry/%E3%85%87)


### 표준화와 정규화의 차이
![정규화와 표준편차](https://devskrol.com/wp-content/uploads/2022/01/image-30-1024x336.png)
![차이 명확히](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuFiP1%2FbtrfoRhJjrp%2Frpu2mJTNe2fLxsQ13MuYBk%2Fimg.webp)


### 왜도와 첨도
![왜도와 첨도](https://blog.kakaocdn.net/dn/cAZHL9/btrqQfRkJX0/l8b2AMfUUJmE4sWjErhh0k/img.jpg)
- negative skewness: 시험점수 (오른쪽으로 쏠림)
- positive skewness: 국민 소득수준 (왼쪽으로 쏠림)

- kurtosis는 클수록 분포가 뾰족하고, 작을수록 분포가 평탄함

